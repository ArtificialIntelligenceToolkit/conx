{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n",
    "\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAPc0lEQVR4nO1dWY/cyJFOkkkWWXdV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\n/R+Z1dd5hPzx7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x7F54F859B668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIL.Image.fromarray(x_train[0]).resize((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conx import *\n",
    "\n",
    "net = Network(\"CIRAR10\")\n",
    "net.add(Layer(\"input\", (32, 32, 3)))\n",
    "net.add(Conv2DLayer(\"conv1\", 32, (3, 3), padding='same', activation='relu'))\n",
    "net.add(Conv2DLayer(\"conv2\", 32, (3, 3), activation='relu'))\n",
    "net.add(MaxPool2DLayer(\"pool1\", pool_size=(2, 2), dropout=0.25))\n",
    "net.add(Conv2DLayer(\"conv3\", 64, (3, 3), padding='same', activation='relu'))\n",
    "net.add(Conv2DLayer(\"conv4\", 64, (3, 3), activation='relu'))\n",
    "net.add(MaxPool2DLayer(\"pool2\", pool_size=(2, 2), dropout=0.25))\n",
    "net.add(FlattenLayer(\"flatten\"))\n",
    "net.add(Layer(\"hidden1\", 512, activation='relu', vshape=(16, 32), dropout=0.5))\n",
    "net.add(Layer(\"output\", num_classes, activation='softmax'))\n",
    "net.connect()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model = net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['base/js/namespace'], function(Jupyter) {\n",
       "    Jupyter.notebook.kernel.comm_manager.register_target('conx_svg_control', function(comm, msg) {\n",
       "        comm.on_msg(function(msg) {\n",
       "            var data = msg[\"content\"][\"data\"];\n",
       "            var images = document.getElementsByClassName(data[\"class\"]);\n",
       "            for (var i = 0; i < images.length; i++) {\n",
       "                images[i].setAttributeNS(null, \"href\", data[\"href\"]);\n",
       "            }\n",
       "        });\n",
       "    });\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b77ff3d3ab4c1e8015687712bfb07d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.build_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.093069039,\n",
       " 0.10011563,\n",
       " 0.095031247,\n",
       " 0.10813325,\n",
       " 0.10609876,\n",
       " 0.098909222,\n",
       " 0.091789804,\n",
       " 0.10413843,\n",
       " 0.096605763,\n",
       " 0.10610884]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   length  : 50000\n",
      "   training: 50000\n",
      "   testing : 0\n",
      "   shape  : (32, 32, 3)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   length  : 50000\n",
      "   training: 50000\n",
      "   testing : 0\n",
      "   shape  : (10,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.set_dataset_direct(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.093362622,\n",
       " 0.097683288,\n",
       " 0.095821574,\n",
       " 0.11152615,\n",
       " 0.10547518,\n",
       " 0.096584819,\n",
       " 0.091399543,\n",
       " 0.10520381,\n",
       " 0.096004292,\n",
       " 0.10693872]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "   9/1562 [..............................] - ETA: 391s - loss: 2.3162 - acc: 0.1111"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d7688794956b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                         validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Load label names to use in prediction results\n",
    "label_list_path = 'datasets/cifar-10-batches-py/batches.meta'\n",
    "\n",
    "\n",
    "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
    "datadir_base = os.path.expanduser(keras_dir)\n",
    "if not os.access(datadir_base, os.W_OK):\n",
    "    datadir_base = os.path.join('/tmp', '.keras')\n",
    "label_list_path = os.path.join(datadir_base, label_list_path)\n",
    "\n",
    "with open(label_list_path, mode='rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Evaluate model with test data set and share sample prediction results\n",
    "evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
    "\n",
    "predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "for predict_index, predicted_y in enumerate(predict_gen):\n",
    "    actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n",
    "    predicted_label = labels['label_names'][np.argmax(predicted_y)]\n",
    "    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n",
    "                                                          predicted_label))\n",
    "    if predict_index == num_predictions:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11d54af7d6da4851a55c5577ebf2c97c": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "height": "100%",
       "justify_content": "center",
       "max_height": "550px",
       "overflow_x": "auto",
       "width": "100%"
      }
     },
     "1256a99ae9c144cabc9a4346aff7380e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "1f6539806c024aa39ec6e7dfb989eb8a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "224453a9269b4d139ba5215781c7d843": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "2ccd28221d5042509c5ea998b840c763": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "4eea65771d394642b28db67a5e3b03a8": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "4fcfb36a186f44eeadf09d35bde39046": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "icon": "forward",
       "layout": "IPY_MODEL_a8267993bc3a43f1a2e6c5d77b4b30d7",
       "style": "IPY_MODEL_75eb15d39a844a00b868b01fefb50e43"
      }
     },
     "521e8bd65b644243b9e63db867719dbe": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "icon": "fast-backward",
       "layout": "IPY_MODEL_1f6539806c024aa39ec6e7dfb989eb8a",
       "style": "IPY_MODEL_4eea65771d394642b28db67a5e3b03a8"
      }
     },
     "53f0dad7e4c54db0887afef145087fcf": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "icon": "Train",
       "layout": "IPY_MODEL_a54cdbcfa23e44eb8c2882b5f011488a",
       "style": "IPY_MODEL_57642574875546558af1e9291b811823"
      }
     },
     "57642574875546558af1e9291b811823": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "6b364a0bb0594e3f8d76df4f67af43a8": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "75eb15d39a844a00b868b01fefb50e43": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "7e98e0e19fbd4786a5a00fec488a5954": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "IntSliderModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "continuous_update": false,
       "description": "Dataset index",
       "layout": "IPY_MODEL_2ccd28221d5042509c5ea998b840c763",
       "max": 0,
       "style": "IPY_MODEL_b28aa496fa3942f4b910d675441f0397"
      }
     },
     "7f777fcc7f22450491315874b140fb2c": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "86d3c768adfa45cda97b529883b83adb": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "SelectModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_options_labels": [
        "Test",
        "Train"
       ],
       "_view_module_version": "~2.1.4",
       "description": "Dataset:",
       "layout": "IPY_MODEL_cdc7cbbd9626447c8578b1dbf52843a4",
       "value": "Train"
      }
     },
     "87811b495ca14648b2f6f3efccdcdeec": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "a54cdbcfa23e44eb8c2882b5f011488a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "a598498b4dda414c99a9d750a9057b87": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_521e8bd65b644243b9e63db867719dbe",
        "IPY_MODEL_df6fac95b02a4849aa101fb67b6f0034",
        "IPY_MODEL_53f0dad7e4c54db0887afef145087fcf",
        "IPY_MODEL_4fcfb36a186f44eeadf09d35bde39046",
        "IPY_MODEL_d3da055cc12a4bec8cbda690083da017"
       ],
       "layout": "IPY_MODEL_ee20448c298d4b438cc51ed6f7df912e"
      }
     },
     "a8267993bc3a43f1a2e6c5d77b4b30d7": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     },
     "b28aa496fa3942f4b910d675441f0397": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "b7d9e2470bdb49c4b8160e5b360d6c18": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "c92b9d7c6bd640ed9669757e44d1f150": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_11d54af7d6da4851a55c5577ebf2c97c",
       "value": "\n        <svg id='CIRAR10' xmlns='http://www.w3.org/2000/svg' width=\"350\" height=\"1945\" image-rendering=\"pixelated\">\n    <defs>\n        <marker id=\"arrow\" markerWidth=\"10\" markerHeight=\"10\" refX=\"9\" refY=\"3\" orient=\"auto\" markerUnits=\"strokeWidth\">\n          <path d=\"M0,0 L0,6 L9,3 z\" fill=\"blue\" />\n        </marker>\n    </defs>\n<rect x=\"74.0\" y=\"24\" width=\"202\" height=\"27\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_output_targets_1\" class=\"CIRAR10_output_targets\" x=\"75.0\" y=\"25\" height=\"25\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhCgABAIAAABkZGQAAACwAAAAACgABAAAIBwABCBxIMCAAOw==\"><title>Layer: output (output)\n shape = (10,)\n Keras class = Dense\n activation = softmax</title></image><text x=\"280.0\" y=\"39.5\" font-family=\"monospace\" font-size=\"12\">targets</text><rect x=\"74.0\" y=\"59\" width=\"202\" height=\"27\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_output_errors_1\" class=\"CIRAR10_output_errors\" x=\"75.0\" y=\"60\" height=\"25\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhCgABAIAAABkZGQAAACwAAAAACgABAAAIBwABCBxIMCAAOw==\"><title>Layer: output (output)\n shape = (10,)\n Keras class = Dense\n activation = softmax</title></image><text x=\"280.0\" y=\"74.5\" font-family=\"monospace\" font-size=\"12\">errors</text><rect x=\"74.0\" y=\"99\" width=\"202\" height=\"27\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_output_1\" class=\"CIRAR10_output\" x=\"75.0\" y=\"100\" height=\"25\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhCgABAIAAABkZGQAAACwAAAAACgABAAAIBwABCBxIMCAAOw==\"><title>Layer: output (output)\n shape = (10,)\n Keras class = Dense\n activation = softmax</title></image><text x=\"280.0\" y=\"114.5\" font-family=\"monospace\" font-size=\"12\">output</text><rect x=\"165.0\" y=\"127\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from hidden1 to output\n output/kernel has shape (512, 10)\n output/bias has shape (10,)</title></rect><line x1=\"175.0\" y1=\"154\" x2=\"175.0\" y2=\"127\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from hidden1 to output\n output/kernel has shape (512, 10)\n output/bias has shape (10,)</title></line><rect x=\"74.0\" y=\"154\" width=\"202\" height=\"102\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_hidden1_2\" class=\"CIRAR10_hidden1\" x=\"75.0\" y=\"155\" height=\"100\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhIAAQAIAAAH9/fwAAACwAAAAAIAAQAEAIJwABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjxADAgA7\"><title>Layer: hidden1 (hidden)\n shape = (512,)\n dropout = 0.5\n Keras class = Dense\n activation = relu</title></image><text x=\"280.0\" y=\"207.0\" font-family=\"monospace\" font-size=\"12\">hidden1</text><rect x=\"165.0\" y=\"257\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from flatten to hidden1\n hidden1/kernel has shape (2304, 512)\n hidden1/bias has shape (512,)</title></rect><line x1=\"175.0\" y1=\"284\" x2=\"175.0\" y2=\"257\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from flatten to hidden1\n hidden1/kernel has shape (2304, 512)\n hidden1/bias has shape (512,)</title></line><rect x=\"74.0\" y=\"284\" width=\"202\" height=\"27\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_flatten_3\" class=\"CIRAR10_flatten\" x=\"75.0\" y=\"285\" height=\"25\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhAAkBAIAAAH9/fwAAACwAAAAAAAkBAAAITwABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDihxJsqTJkyhTqlzJsqXLlzBjypxJs6bNmzhz6tzJs6fPn0CDCh2qMSAAOw==\"><title>Layer: flatten (hidden)\n Keras class = Flatten</title></image><text x=\"280.0\" y=\"299.5\" font-family=\"monospace\" font-size=\"12\">flatten</text><rect x=\"165.0\" y=\"312\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from pool2 to flatten</title></rect><line x1=\"175.0\" y1=\"339\" x2=\"175.0\" y2=\"312\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from pool2 to flatten</title></line><rect x=\"74.0\" y=\"339\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_pool2_4\" class=\"CIRAR10_pool2\" x=\"75.0\" y=\"340\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhBgAGAIAAAH9/fwAAACwAAAAABgAGAAAIDAABCBxIsKDBgwgDAgA7\"><title>Layer: pool2 (hidden)\n dropout = 0.25\n Keras class = MaxPooling2D\n pool_size = (2, 2)</title></image><text x=\"280.0\" y=\"442.0\" font-family=\"monospace\" font-size=\"12\">pool2</text><rect x=\"165.0\" y=\"542\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from conv4 to pool2</title></rect><line x1=\"175.0\" y1=\"569\" x2=\"175.0\" y2=\"542\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from conv4 to pool2</title></line><rect x=\"74.0\" y=\"569\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_conv4_5\" class=\"CIRAR10_conv4\" x=\"75.0\" y=\"570\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhDQANAIAAAH9/fwAAACwAAAAADQANAAAIFwABCBxIsKDBgwgTKlzIsKHDhxAjQgwIADs=\"><title>Layer: conv4 (hidden)\n Keras class = Conv2D\n activation = relu</title></image><text x=\"280.0\" y=\"672.0\" font-family=\"monospace\" font-size=\"12\">conv4</text><rect x=\"165.0\" y=\"772\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from conv3 to conv4\n conv4/kernel has shape (3, 3, 64, 64)\n conv4/bias has shape (64,)</title></rect><line x1=\"175.0\" y1=\"799\" x2=\"175.0\" y2=\"772\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from conv3 to conv4\n conv4/kernel has shape (3, 3, 64, 64)\n conv4/bias has shape (64,)</title></line><rect x=\"74.0\" y=\"799\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_conv3_6\" class=\"CIRAR10_conv3\" x=\"75.0\" y=\"800\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhDwAPAIAAAH9/fwAAACwAAAAADwAPAAAIGgABCBxIsKDBgwgTKlzIsKHDhxAjSpxI8WFAADs=\"><title>Layer: conv3 (hidden)\n Keras class = Conv2D\n padding = same\n activation = relu</title></image><text x=\"280.0\" y=\"902.0\" font-family=\"monospace\" font-size=\"12\">conv3</text><rect x=\"165.0\" y=\"1002\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from pool1 to conv3\n conv3/kernel has shape (3, 3, 32, 64)\n conv3/bias has shape (64,)</title></rect><line x1=\"175.0\" y1=\"1029\" x2=\"175.0\" y2=\"1002\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from pool1 to conv3\n conv3/kernel has shape (3, 3, 32, 64)\n conv3/bias has shape (64,)</title></line><rect x=\"74.0\" y=\"1029\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_pool1_7\" class=\"CIRAR10_pool1\" x=\"75.0\" y=\"1030\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhDwAPAIAAAH9/fwAAACwAAAAADwAPAAAIGgABCBxIsKDBgwgTKlzIsKHDhxAjSpxI8WFAADs=\"><title>Layer: pool1 (hidden)\n dropout = 0.25\n Keras class = MaxPooling2D\n pool_size = (2, 2)</title></image><text x=\"280.0\" y=\"1132.0\" font-family=\"monospace\" font-size=\"12\">pool1</text><rect x=\"165.0\" y=\"1232\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from conv2 to pool1</title></rect><line x1=\"175.0\" y1=\"1259\" x2=\"175.0\" y2=\"1232\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from conv2 to pool1</title></line><rect x=\"74.0\" y=\"1259\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_conv2_8\" class=\"CIRAR10_conv2\" x=\"75.0\" y=\"1260\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhHgAeAIAAAH9/fwAAACwAAAAAHgAeAEAIMgABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDihxJsqTJkyhTngwIADs=\"><title>Layer: conv2 (hidden)\n Keras class = Conv2D\n activation = relu</title></image><text x=\"280.0\" y=\"1362.0\" font-family=\"monospace\" font-size=\"12\">conv2</text><rect x=\"165.0\" y=\"1462\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from conv1 to conv2\n conv2/kernel has shape (3, 3, 32, 32)\n conv2/bias has shape (32,)</title></rect><line x1=\"175.0\" y1=\"1489\" x2=\"175.0\" y2=\"1462\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from conv1 to conv2\n conv2/kernel has shape (3, 3, 32, 32)\n conv2/bias has shape (32,)</title></line><rect x=\"74.0\" y=\"1489\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_conv1_9\" class=\"CIRAR10_conv1\" x=\"75.0\" y=\"1490\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhIAAgAIAAAH9/fwAAACwAAAAAIAAgAEAINQABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDihxJsqTJkyhTqlzJUmRAADs=\"><title>Layer: conv1 (hidden)\n Keras class = Conv2D\n padding = same\n activation = relu</title></image><text x=\"280.0\" y=\"1592.0\" font-family=\"monospace\" font-size=\"12\">conv1</text><rect x=\"165.0\" y=\"1692\" width=\"20.0\" height=\"27\" style=\"fill:white;stroke:none\"><title>Weights from input to conv1\n conv1/kernel has shape (3, 3, 3, 32)\n conv1/bias has shape (32,)</title></rect><line x1=\"175.0\" y1=\"1719\" x2=\"175.0\" y2=\"1692\" stroke=\"blue\" stroke-width=\"2\" marker-end=\"url(#arrow)\"><title>Weights from input to conv1\n conv1/kernel has shape (3, 3, 3, 32)\n conv1/bias has shape (32,)</title></line><rect x=\"74.0\" y=\"1719\" width=\"202\" height=\"202\" style=\"fill:none;stroke:blue;stroke-width:2\"/><image id=\"CIRAR10_input_10\" class=\"CIRAR10_input\" x=\"75.0\" y=\"1720\" height=\"200\" width=\"200\" preserveAspectRatio=\"none\" href=\"data:image/gif;base64,R0lGODdhIAAgAIAAAH9/fwAAACwAAAAAIAAgAEAINQABCBxIsKDBgwgTKlzIsKHDhxAjSpxIsaLFixgzatzIsaPHjyBDihxJsqTJkyhTqlzJUmRAADs=\"><title>Layer: input (input)\n shape = (32, 32, 3)\n Keras class = Input</title></image><text x=\"280.0\" y=\"1822.0\" font-family=\"monospace\" font-size=\"12\">input</text></svg>"
      }
     },
     "cdc7cbbd9626447c8578b1dbf52843a4": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "d3da055cc12a4bec8cbda690083da017": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "icon": "fast-forward",
       "layout": "IPY_MODEL_224453a9269b4d139ba5215781c7d843",
       "style": "IPY_MODEL_1256a99ae9c144cabc9a4346aff7380e"
      }
     },
     "d6e42cbfab2f4cf6849f6275522cb024": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "VBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_86d3c768adfa45cda97b529883b83adb",
        "IPY_MODEL_7e98e0e19fbd4786a5a00fec488a5954",
        "IPY_MODEL_a598498b4dda414c99a9d750a9057b87"
       ],
       "layout": "IPY_MODEL_7f777fcc7f22450491315874b140fb2c"
      }
     },
     "df6fac95b02a4849aa101fb67b6f0034": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ButtonModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "icon": "backward",
       "layout": "IPY_MODEL_6b364a0bb0594e3f8d76df4f67af43a8",
       "style": "IPY_MODEL_b7d9e2470bdb49c4b8160e5b360d6c18"
      }
     },
     "e5b77ff3d3ab4c1e8015687712bfb07d": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "VBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_c92b9d7c6bd640ed9669757e44d1f150",
        "IPY_MODEL_d6e42cbfab2f4cf6849f6275522cb024"
       ],
       "layout": "IPY_MODEL_87811b495ca14648b2f6f3efccdcdeec"
      }
     },
     "ee20448c298d4b438cc51ed6f7df912e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "width": "100%"
      }
     }
    },
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
