{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "A dataset is a list of (input, target) pairs that can be further split into training and testing lists.\n",
    "\n",
    "Let's make an example network to use as demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Summary\n",
      "---------------\n",
      "Network name: Odd Network\n",
      "    Layer name: 'input' (input)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Connected to: ['hidden']\n",
      "        Activation function: None\n",
      "        Dropout percent: 0\n",
      "    Layer name: 'hidden' (hidden)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Connected to: ['output']\n",
      "        Activation function: relu\n",
      "        Dropout percent: 0\n",
      "    Layer name: 'output' (output)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Activation function: sigmoid\n",
      "        Dropout percent: 0\n"
     ]
    }
   ],
   "source": [
    "from conx import Network, Layer\n",
    "\n",
    "net = Network(\"Odd Network\")\n",
    "net.add(Layer(\"input\", 5))\n",
    "net.add(Layer(\"hidden\", 2, activation=\"relu\"))\n",
    "net.add(Layer(\"output\", 1, activation=\"sigmoid\"))\n",
    "net.connect()\n",
    "net.compile(error=\"mse\", optimizer=\"adam\")\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a list of (input, target) pairs\n",
    "\n",
    "The most straightforward method of adding input, target vectors to train on is to use a list of (input, target) pairs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = []\n",
    "\n",
    "for i in range(2 ** 5):\n",
    "    inputs = [int(s) for s in (\"00000\" + bin(i)[2:])[-5:]]\n",
    "    targets = [int((i % 2 == 1))]\n",
    "    patterns.append((inputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 1, 0, 1], [1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.set_dataset(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (5,)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (1,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset.add()\n",
    "\n",
    "You can use the default `dataset` and add one pattern at a time. Consider the task of training a network to determine if the number of inputs is even (0) or odd (1). We could add inputs one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.dataset.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.dataset.add([0, 0, 0, 0, 1], [1])\n",
    "net.dataset.add([0, 0, 0, 1, 1], [0])\n",
    "net.dataset.add([0, 0, 1, 0, 0], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.dataset.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2 ** 5):\n",
    "    inputs = [int(s) for s in (\"00000\" + bin(i)[2:])[-5:]]\n",
    "    targets = [int((i % 2 == 1))]\n",
    "    net.dataset.add(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (5,)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (1,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dataset.inputs[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dataset.targets[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch #  100 | train error 0.25526 | train accuracy 0.40625 | validate% 0.00000\n",
      "Epoch #  200 | train error 0.22707 | train accuracy 0.71875 | validate% 0.00000\n",
      "Epoch #  300 | train error 0.20312 | train accuracy 0.78125 | validate% 0.00000\n",
      "Epoch #  400 | train error 0.18106 | train accuracy 0.81250 | validate% 0.03125\n",
      "Epoch #  500 | train error 0.15291 | train accuracy 0.84375 | validate% 0.06250\n",
      "Epoch #  600 | train error 0.11817 | train accuracy 0.96875 | validate% 0.09375\n",
      "Epoch #  700 | train error 0.08046 | train accuracy 1.00000 | validate% 0.25000\n",
      "Epoch #  800 | train error 0.05537 | train accuracy 1.00000 | validate% 0.43750\n",
      "Epoch #  900 | train error 0.03762 | train accuracy 1.00000 | validate% 0.65625\n",
      "========================================================================\n",
      "Epoch #  954 | train error 0.03062 | train accuracy 1.00000 | validate% 0.75000\n"
     ]
    }
   ],
   "source": [
    "net.train(epochs=5000, accuracy=.75, tolerance=.2, report_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.3] | X\n",
      "1 | [0.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | X\n",
      "2 | [0.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "3 | [0.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "4 | [0.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "5 | [0.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "6 | [0.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "7 | [0.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "8 | [0.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | correct\n",
      "9 | [0.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "10 | [0.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "11 | [0.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "12 | [0.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "13 | [0.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "14 | [0.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "15 | [0.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "16 | [1.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "17 | [1.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.7] | X\n",
      "18 | [1.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "19 | [1.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | X\n",
      "20 | [1.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "21 | [1.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "22 | [1.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "23 | [1.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "24 | [1.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "25 | [1.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "26 | [1.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "27 | [1.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "28 | [1.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "29 | [1.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "30 | [1.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "31 | [1.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset()\n",
    "\n",
    "You can also create, and switch between, independent datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conx import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2 ** 5):\n",
    "    inputs = [int(s) for s in (\"00000\" + bin(i)[2:])[-5:]]\n",
    "    targets = [int((i % 2 == 1))]\n",
    "    ds.add(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, you can set the dataset, but using the Datatset object rather than list of (input, target) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.set_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.3] | X\n",
      "1 | [0.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | X\n",
      "2 | [0.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "3 | [0.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "4 | [0.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "5 | [0.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "6 | [0.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "7 | [0.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "8 | [0.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | correct\n",
      "9 | [0.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "10 | [0.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "11 | [0.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "12 | [0.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "13 | [0.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "14 | [0.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "15 | [0.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "16 | [1.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "17 | [1.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.7] | X\n",
      "18 | [1.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "19 | [1.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | X\n",
      "20 | [1.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "21 | [1.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "22 | [1.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "23 | [1.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "24 | [1.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "25 | [1.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "26 | [1.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "27 | [1.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "28 | [1.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "29 | [1.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "30 | [1.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "31 | [1.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset inputs and targets\n",
    "\n",
    "Inputs and targets in the dataset are represented (both in accessing and in assignemnt) in the same format as given (as lists, or lists of lists). These formats are automattically converted into an internal format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.inputs[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.inputs[17] = [0.9, 0.1, 0.1, 0.1, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.3] | X\n",
      "1 | [0.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | X\n",
      "2 | [0.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "3 | [0.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "4 | [0.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "5 | [0.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "6 | [0.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "7 | [0.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "8 | [0.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | correct\n",
      "9 | [0.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "10 | [0.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "11 | [0.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "12 | [0.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "13 | [0.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "14 | [0.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "15 | [0.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "16 | [1.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "17 | [0.9, 0.1, 0.1, 0.1, 0.9] | [1.0] | [0.7] | X\n",
      "18 | [1.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "19 | [1.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | X\n",
      "20 | [1.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "21 | [1.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "22 | [1.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "23 | [1.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "24 | [1.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "25 | [1.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "26 | [1.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "27 | [1.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "28 | [1.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "29 | [1.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "30 | [1.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "31 | [1.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see/access the internal format, use the underscore before inputs or targets. This is a numpy array. conx is designed so that you need not have to use numpy for most network operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89999998,  0.1       ,  0.1       ,  0.1       ,  0.89999998], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds._inputs[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = Dataset.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10 = Dataset.get_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "168984576/169001437 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "cifar100 = Dataset.get_cifar100()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset operations\n",
    "\n",
    "Dataset.split() will divide the dataset between training and testing sets. You can provide split an integer (to divide at a specific point), or a floating-point value, to divide by a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.split(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.split(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.slice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional operations\n",
    "\n",
    "These functions are subject to change to an API which is more general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.set_targets_from_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.set_inputs_from_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.set_targets_from_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.reshape_inputs(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset direct manipulation\n",
    "\n",
    "You can also set the internal format directly, given that it is in the correct format:\n",
    "\n",
    "* use list of columns for multi-bank inputs or targets\n",
    "* use np.array(vectors) for single-bank inputs or targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(2 ** 5):\n",
    "    inputs.append([int(s) for s in (\"00000\" + bin(i)[2:])[-5:]])\n",
    "    targets.append([int((i % 2 == 1))])\n",
    "\n",
    "ds.load_direct(np.array(inputs), np.array(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.set_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.3] | X\n",
      "1 | [0.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | X\n",
      "2 | [0.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "3 | [0.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "4 | [0.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "5 | [0.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "6 | [0.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.2] | X\n",
      "7 | [0.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "8 | [0.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | correct\n",
      "9 | [0.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "10 | [0.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "11 | [0.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "12 | [0.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "13 | [0.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "14 | [0.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "15 | [0.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "16 | [1.0, 0.0, 0.0, 0.0, 0.0] | [0.0] | [0.2] | X\n",
      "17 | [1.0, 0.0, 0.0, 0.0, 1.0] | [1.0] | [0.7] | X\n",
      "18 | [1.0, 0.0, 0.0, 1.0, 0.0] | [0.0] | [0.2] | correct\n",
      "19 | [1.0, 0.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | X\n",
      "20 | [1.0, 0.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "21 | [1.0, 0.0, 1.0, 0.0, 1.0] | [1.0] | [0.9] | correct\n",
      "22 | [1.0, 0.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "23 | [1.0, 0.0, 1.0, 1.0, 1.0] | [1.0] | [0.9] | correct\n",
      "24 | [1.0, 1.0, 0.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "25 | [1.0, 1.0, 0.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "26 | [1.0, 1.0, 0.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "27 | [1.0, 1.0, 0.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "28 | [1.0, 1.0, 1.0, 0.0, 0.0] | [0.0] | [0.1] | correct\n",
      "29 | [1.0, 1.0, 1.0, 0.0, 1.0] | [1.0] | [0.8] | correct\n",
      "30 | [1.0, 1.0, 1.0, 1.0, 0.0] | [0.0] | [0.1] | correct\n",
      "31 | [1.0, 1.0, 1.0, 1.0, 1.0] | [1.0] | [0.8] | correct\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
