{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "A dataset is a list of (input, target) pairs that can be further split into training and testing lists.\n",
    "\n",
    "Let's make an example network to use as demonstration. This network will compute whether the number of 1's in a set of 5 bits is odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Summary\n",
      "---------------\n",
      "Network name: Odd Network\n",
      "    Layer name: 'input' (input)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Connected to: ['hidden']\n",
      "        Activation function: None\n",
      "        Dropout percent: 0\n",
      "    Layer name: 'hidden' (hidden)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Connected to: ['output']\n",
      "        Activation function: relu\n",
      "        Dropout percent: 0\n",
      "    Layer name: 'output' (output)\n",
      "        VShape: None\n",
      "        Dropout: 0\n",
      "        Activation function: sigmoid\n",
      "        Dropout percent: 0\n"
     ]
    }
   ],
   "source": [
    "from conx import Network, Layer\n",
    "\n",
    "net = Network(\"Odd Network\")\n",
    "net.add(Layer(\"input\", 5))\n",
    "net.add(Layer(\"hidden\", 10, activation=\"relu\"))\n",
    "net.add(Layer(\"output\", 1, activation=\"sigmoid\"))\n",
    "net.connect()\n",
    "net.compile(error=\"mse\", optimizer=\"adam\")\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a list of (input, target) pairs\n",
    "\n",
    "The most straightforward method of adding input, target vectors to train on is to use a list of (input, target) pairs. First we define a function that takes a number and returns the bitwise representation of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2bin(i, bits=5):\n",
    "    \"\"\"\n",
    "    Take a number and turn it into a list of bits (most significant first).\n",
    "    \"\"\"\n",
    "    return [int(s) for s in ((\"0\" * bits) + bin(i)[2:])[-bits:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2bin(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a list of (input, target) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "\n",
    "for i in range(2 ** 5):\n",
    "    inputs = num2bin(i)\n",
    "    targets = [int(sum(inputs) % 2 == 1.0)]\n",
    "    patterns.append((inputs, targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair set 5 looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 1, 0, 1], [0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the network to use this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 0, 0, 0], [0]),\n",
       " ([0, 0, 0, 0, 1], [1]),\n",
       " ([0, 0, 0, 1, 0], [1]),\n",
       " ([0, 0, 0, 1, 1], [0]),\n",
       " ([0, 0, 1, 0, 0], [1]),\n",
       " ([0, 0, 1, 0, 1], [0]),\n",
       " ([0, 0, 1, 1, 0], [0]),\n",
       " ([0, 0, 1, 1, 1], [1]),\n",
       " ([0, 1, 0, 0, 0], [1]),\n",
       " ([0, 1, 0, 0, 1], [0]),\n",
       " ([0, 1, 0, 1, 0], [0]),\n",
       " ([0, 1, 0, 1, 1], [1]),\n",
       " ([0, 1, 1, 0, 0], [0]),\n",
       " ([0, 1, 1, 0, 1], [1]),\n",
       " ([0, 1, 1, 1, 0], [1]),\n",
       " ([0, 1, 1, 1, 1], [0]),\n",
       " ([1, 0, 0, 0, 0], [1]),\n",
       " ([1, 0, 0, 0, 1], [0]),\n",
       " ([1, 0, 0, 1, 0], [0]),\n",
       " ([1, 0, 0, 1, 1], [1]),\n",
       " ([1, 0, 1, 0, 0], [0]),\n",
       " ([1, 0, 1, 0, 1], [1]),\n",
       " ([1, 0, 1, 1, 0], [1]),\n",
       " ([1, 0, 1, 1, 1], [0]),\n",
       " ([1, 1, 0, 0, 0], [0]),\n",
       " ([1, 1, 0, 0, 1], [1]),\n",
       " ([1, 1, 0, 1, 0], [1]),\n",
       " ([1, 1, 0, 1, 1], [0]),\n",
       " ([1, 1, 1, 0, 0], [1]),\n",
       " ([1, 1, 1, 0, 1], [0]),\n",
       " ([1, 1, 1, 1, 0], [0]),\n",
       " ([1, 1, 1, 1, 1], [1])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.load(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (5,)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (1,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset.add()\n",
    "\n",
    "You can use the default `dataset` and add one pattern at a time. Consider the task of training a network to determine if the number of inputs is even (0) or odd (1). We could add inputs one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.add([0, 0, 0, 0, 1], [1])\n",
    "net.dataset.add([0, 0, 0, 1, 1], [0])\n",
    "net.dataset.add([0, 0, 1, 0, 0], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2 ** 5):\n",
    "    inputs = num2bin(i)\n",
    "    targets = [int(sum(inputs) % 2 == 1.0)]\n",
    "    net.dataset.add(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (5,)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   count  : 32 (32 for training, 0 for testing)\n",
      "   shape  : (1,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dataset.inputs[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dataset.targets[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch #  100 | train error 0.25057 | train accuracy 0.56250 | validate% 0.00000\n",
      "Epoch #  200 | train error 0.24481 | train accuracy 0.56250 | validate% 0.00000\n",
      "Epoch #  300 | train error 0.24008 | train accuracy 0.50000 | validate% 0.00000\n",
      "Epoch #  400 | train error 0.23402 | train accuracy 0.59375 | validate% 0.00000\n",
      "Epoch #  500 | train error 0.22551 | train accuracy 0.71875 | validate% 0.00000\n",
      "Epoch #  600 | train error 0.21735 | train accuracy 0.75000 | validate% 0.00000\n",
      "Epoch #  700 | train error 0.20895 | train accuracy 0.78125 | validate% 0.00000\n",
      "Epoch #  800 | train error 0.20028 | train accuracy 0.84375 | validate% 0.00000\n",
      "Epoch #  900 | train error 0.19143 | train accuracy 0.87500 | validate% 0.00000\n",
      "Epoch # 1000 | train error 0.18276 | train accuracy 0.87500 | validate% 0.00000\n",
      "Epoch # 1100 | train error 0.17386 | train accuracy 0.87500 | validate% 0.00000\n",
      "Epoch # 1200 | train error 0.16527 | train accuracy 0.87500 | validate% 0.00000\n",
      "Epoch # 1300 | train error 0.15444 | train accuracy 0.87500 | validate% 0.06250\n",
      "Epoch # 1400 | train error 0.14588 | train accuracy 0.87500 | validate% 0.09375\n",
      "Epoch # 1500 | train error 0.13851 | train accuracy 0.90625 | validate% 0.12500\n",
      "Epoch # 1600 | train error 0.13196 | train accuracy 0.90625 | validate% 0.15625\n",
      "Epoch # 1700 | train error 0.12605 | train accuracy 0.93750 | validate% 0.25000\n",
      "Epoch # 1800 | train error 0.12062 | train accuracy 0.93750 | validate% 0.25000\n",
      "Epoch # 1900 | train error 0.11559 | train accuracy 0.93750 | validate% 0.25000\n",
      "Epoch # 2000 | train error 0.11081 | train accuracy 0.93750 | validate% 0.28125\n",
      "Epoch # 2100 | train error 0.10627 | train accuracy 0.93750 | validate% 0.31250\n",
      "Epoch # 2200 | train error 0.10193 | train accuracy 0.93750 | validate% 0.31250\n",
      "Epoch # 2300 | train error 0.09784 | train accuracy 0.93750 | validate% 0.31250\n",
      "Epoch # 2400 | train error 0.09393 | train accuracy 0.93750 | validate% 0.37500\n",
      "Epoch # 2500 | train error 0.09018 | train accuracy 0.93750 | validate% 0.43750\n",
      "Epoch # 2600 | train error 0.08565 | train accuracy 0.93750 | validate% 0.46875\n",
      "Epoch # 2700 | train error 0.08102 | train accuracy 0.93750 | validate% 0.50000\n",
      "Epoch # 2800 | train error 0.07668 | train accuracy 0.93750 | validate% 0.50000\n",
      "Epoch # 2900 | train error 0.07279 | train accuracy 0.93750 | validate% 0.50000\n",
      "Epoch # 3000 | train error 0.06629 | train accuracy 0.96875 | validate% 0.53125\n",
      "Epoch # 3100 | train error 0.06223 | train accuracy 0.96875 | validate% 0.56250\n",
      "Epoch # 3200 | train error 0.05920 | train accuracy 0.96875 | validate% 0.59375\n",
      "Epoch # 3300 | train error 0.05670 | train accuracy 0.96875 | validate% 0.68750\n",
      "Epoch # 3400 | train error 0.05456 | train accuracy 0.96875 | validate% 0.68750\n",
      "========================================================================\n",
      "Epoch # 3467 | train error 0.05329 | train accuracy 0.96875 | validate% 0.75000\n"
     ]
    }
   ],
   "source": [
    "net.train(epochs=5000, accuracy=.75, tolerance=.2, report_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.00,0.00,0.00,0.00,0.00] | [0.00] | [0.02] | correct\n",
      "1 | [0.00,0.00,0.00,0.00,1.00] | [1.00] | [0.93] | correct\n",
      "2 | [0.00,0.00,0.00,1.00,0.00] | [1.00] | [0.83] | correct\n",
      "3 | [0.00,0.00,0.00,1.00,1.00] | [0.00] | [0.14] | correct\n",
      "4 | [0.00,0.00,1.00,0.00,0.00] | [1.00] | [0.95] | correct\n",
      "5 | [0.00,0.00,1.00,0.00,1.00] | [0.00] | [0.08] | correct\n",
      "6 | [0.00,0.00,1.00,1.00,0.00] | [0.00] | [0.13] | correct\n",
      "7 | [0.00,0.00,1.00,1.00,1.00] | [1.00] | [0.99] | correct\n",
      "8 | [0.00,1.00,0.00,0.00,0.00] | [1.00] | [0.81] | correct\n",
      "9 | [0.00,1.00,0.00,0.00,1.00] | [0.00] | [0.04] | correct\n",
      "10 | [0.00,1.00,0.00,1.00,0.00] | [0.00] | [0.24] | X\n",
      "11 | [0.00,1.00,0.00,1.00,1.00] | [1.00] | [0.82] | correct\n",
      "12 | [0.00,1.00,1.00,0.00,0.00] | [0.00] | [0.07] | correct\n",
      "13 | [0.00,1.00,1.00,0.00,1.00] | [1.00] | [0.86] | correct\n",
      "14 | [0.00,1.00,1.00,1.00,0.00] | [1.00] | [0.93] | correct\n",
      "15 | [0.00,1.00,1.00,1.00,1.00] | [0.00] | [0.15] | correct\n",
      "16 | [1.00,0.00,0.00,0.00,0.00] | [1.00] | [0.88] | correct\n",
      "17 | [1.00,0.00,0.00,0.00,1.00] | [0.00] | [0.14] | correct\n",
      "18 | [1.00,0.00,0.00,1.00,0.00] | [0.00] | [0.17] | correct\n",
      "19 | [1.00,0.00,0.00,1.00,1.00] | [1.00] | [0.80] | correct\n",
      "20 | [1.00,0.00,1.00,0.00,0.00] | [0.00] | [0.11] | correct\n",
      "21 | [1.00,0.00,1.00,0.00,1.00] | [1.00] | [0.99] | correct\n",
      "22 | [1.00,0.00,1.00,1.00,0.00] | [1.00] | [0.60] | X\n",
      "23 | [1.00,0.00,1.00,1.00,1.00] | [0.00] | [0.36] | X\n",
      "24 | [1.00,1.00,0.00,0.00,0.00] | [0.00] | [0.21] | X\n",
      "25 | [1.00,1.00,0.00,0.00,1.00] | [1.00] | [0.82] | correct\n",
      "26 | [1.00,1.00,0.00,1.00,0.00] | [1.00] | [0.78] | X\n",
      "27 | [1.00,1.00,0.00,1.00,1.00] | [0.00] | [0.28] | X\n",
      "28 | [1.00,1.00,1.00,0.00,0.00] | [1.00] | [0.91] | correct\n",
      "29 | [1.00,1.00,1.00,0.00,1.00] | [0.00] | [0.17] | correct\n",
      "30 | [1.00,1.00,1.00,1.00,0.00] | [0.00] | [0.36] | X\n",
      "31 | [1.00,1.00,1.00,1.00,1.00] | [1.00] | [0.17] | X\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset inputs and targets\n",
    "\n",
    "Inputs and targets in the dataset are represented in the same format as given (as lists, or lists of lists). These formats are automattically converted into an internal format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = net.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.inputs[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0.00,0.00,0.00,0.00,0.00] | [0.00] | [0.02] | correct\n",
      "1 | [0.00,0.00,0.00,0.00,1.00] | [1.00] | [0.93] | correct\n",
      "2 | [0.00,0.00,0.00,1.00,0.00] | [1.00] | [0.83] | correct\n",
      "3 | [0.00,0.00,0.00,1.00,1.00] | [0.00] | [0.14] | correct\n",
      "4 | [0.00,0.00,1.00,0.00,0.00] | [1.00] | [0.95] | correct\n",
      "5 | [0.00,0.00,1.00,0.00,1.00] | [0.00] | [0.08] | correct\n",
      "6 | [0.00,0.00,1.00,1.00,0.00] | [0.00] | [0.13] | correct\n",
      "7 | [0.00,0.00,1.00,1.00,1.00] | [1.00] | [0.99] | correct\n",
      "8 | [0.00,1.00,0.00,0.00,0.00] | [1.00] | [0.81] | correct\n",
      "9 | [0.00,1.00,0.00,0.00,1.00] | [0.00] | [0.04] | correct\n",
      "10 | [0.00,1.00,0.00,1.00,0.00] | [0.00] | [0.24] | X\n",
      "11 | [0.00,1.00,0.00,1.00,1.00] | [1.00] | [0.82] | correct\n",
      "12 | [0.00,1.00,1.00,0.00,0.00] | [0.00] | [0.07] | correct\n",
      "13 | [0.00,1.00,1.00,0.00,1.00] | [1.00] | [0.86] | correct\n",
      "14 | [0.00,1.00,1.00,1.00,0.00] | [1.00] | [0.93] | correct\n",
      "15 | [0.00,1.00,1.00,1.00,1.00] | [0.00] | [0.15] | correct\n",
      "16 | [1.00,0.00,0.00,0.00,0.00] | [1.00] | [0.88] | correct\n",
      "17 | [1.00,0.00,0.00,0.00,1.00] | [0.00] | [0.14] | correct\n",
      "18 | [1.00,0.00,0.00,1.00,0.00] | [0.00] | [0.17] | correct\n",
      "19 | [1.00,0.00,0.00,1.00,1.00] | [1.00] | [0.80] | correct\n",
      "20 | [1.00,0.00,1.00,0.00,0.00] | [0.00] | [0.11] | correct\n",
      "21 | [1.00,0.00,1.00,0.00,1.00] | [1.00] | [0.99] | correct\n",
      "22 | [1.00,0.00,1.00,1.00,0.00] | [1.00] | [0.60] | X\n",
      "23 | [1.00,0.00,1.00,1.00,1.00] | [0.00] | [0.36] | X\n",
      "24 | [1.00,1.00,0.00,0.00,0.00] | [0.00] | [0.21] | X\n",
      "25 | [1.00,1.00,0.00,0.00,1.00] | [1.00] | [0.82] | correct\n",
      "26 | [1.00,1.00,0.00,1.00,0.00] | [1.00] | [0.78] | X\n",
      "27 | [1.00,1.00,0.00,1.00,1.00] | [0.00] | [0.28] | X\n",
      "28 | [1.00,1.00,1.00,0.00,0.00] | [1.00] | [0.91] | correct\n",
      "29 | [1.00,1.00,1.00,0.00,1.00] | [0.00] | [0.17] | correct\n",
      "30 | [1.00,1.00,1.00,1.00,0.00] | [0.00] | [0.36] | X\n",
      "31 | [1.00,1.00,1.00,1.00,1.00] | [1.00] | [0.17] | X\n",
      "Total count: 32\n",
      "Total percentage correct: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see/access the internal format, use the underscore before inputs or targets. This is a numpy array. conx is designed so that you need not have to use numpy for most network operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds._inputs[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conx import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset(net).get('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset(net).get('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset(net).get('cifar100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset operations\n",
    "\n",
    "Dataset.split() will divide the dataset between training and testing sets. You can provide split an integer (to divide at a specific point), or a floating-point value, to divide by a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.split(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.split(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.slice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.chop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   count  : 5 (0 for training, 5 for testing)\n",
      "   shape  : (5,)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   count  : 5 (0 for training, 5 for testing)\n",
      "   shape  : (1,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional operations\n",
    "\n",
    "These functions are subject to change to an API which is more general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_targets_from_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_inputs_from_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.set_targets_from_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.inputs.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.inputs.reshape(0, (1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.inputs.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset direct manipulation\n",
    "\n",
    "You can also set the internal format directly, given that it is in the correct format:\n",
    "\n",
    "* use list of columns for multi-bank inputs or targets\n",
    "* use np.array(vectors) for single-bank inputs or targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(2 ** 5):\n",
    "    v = num2bin(i)\n",
    "    inputs.append(v)\n",
    "    targets.append([int(sum(v) % 2 == 1.0)])\n",
    "\n",
    "net = Network(\"Even?\", 5, 2, 2, 1)\n",
    "net.compile(error=\"mse\", optimizer=\"adam\")\n",
    "net.dataset.load_direct(np.array(inputs), np.array(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training dataset...\n",
      "# | inputs | targets | outputs | result\n",
      "---------------------------------------\n",
      "0 | [0,0,0,0,0] | [0] | [0.00] | correct\n",
      "1 | [0,0,0,0,1] | [1] | [0.28] | X\n",
      "2 | [0,0,0,1,0] | [1] | [-0.08] | X\n",
      "3 | [0,0,0,1,1] | [0] | [0.20] | X\n",
      "4 | [0,0,1,0,0] | [1] | [0.17] | X\n",
      "5 | [0,0,1,0,1] | [0] | [0.45] | X\n",
      "6 | [0,0,1,1,0] | [0] | [0.09] | correct\n",
      "7 | [0,0,1,1,1] | [1] | [0.37] | X\n",
      "8 | [0,1,0,0,0] | [1] | [-0.29] | X\n",
      "9 | [0,1,0,0,1] | [0] | [-0.01] | correct\n",
      "10 | [0,1,0,1,0] | [0] | [-0.37] | X\n",
      "11 | [0,1,0,1,1] | [1] | [-0.09] | X\n",
      "12 | [0,1,1,0,0] | [0] | [-0.13] | correct\n",
      "13 | [0,1,1,0,1] | [1] | [0.15] | X\n",
      "14 | [0,1,1,1,0] | [1] | [-0.20] | X\n",
      "15 | [0,1,1,1,1] | [0] | [0.08] | correct\n",
      "16 | [1,0,0,0,0] | [1] | [0.22] | X\n",
      "17 | [1,0,0,0,1] | [0] | [0.50] | X\n",
      "18 | [1,0,0,1,0] | [0] | [0.14] | correct\n",
      "19 | [1,0,0,1,1] | [1] | [0.42] | X\n",
      "20 | [1,0,1,0,0] | [0] | [0.38] | X\n",
      "21 | [1,0,1,0,1] | [1] | [0.66] | X\n",
      "22 | [1,0,1,1,0] | [1] | [0.31] | X\n",
      "23 | [1,0,1,1,1] | [0] | [0.59] | X\n",
      "24 | [1,1,0,0,0] | [0] | [-0.07] | correct\n",
      "25 | [1,1,0,0,1] | [1] | [0.21] | X\n",
      "26 | [1,1,0,1,0] | [1] | [-0.15] | X\n",
      "27 | [1,1,0,1,1] | [0] | [0.13] | correct\n",
      "28 | [1,1,1,0,0] | [1] | [0.09] | X\n",
      "29 | [1,1,1,0,1] | [0] | [0.37] | X\n",
      "30 | [1,1,1,1,0] | [0] | [0.02] | correct\n",
      "31 | [1,1,1,1,1] | [1] | [0.30] | X\n",
      "Total count: 32\n",
      "Total percentage correct: 0.28125\n"
     ]
    }
   ],
   "source": [
    "net.test(tolerance=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
