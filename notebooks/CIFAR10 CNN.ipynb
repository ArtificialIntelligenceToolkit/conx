{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n",
    "\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAPc0lEQVR4nO1dWY/cyJFOkkkWWXdV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\n/R+Z1dd5hPzx7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x7F93437E2400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIL.Image.fromarray(x_train[0]).resize((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conx import *\n",
    "\n",
    "net = Network(\"CIRAR10\")\n",
    "net.add(Layer(\"input\", (32, 32, 3)))\n",
    "net.add(Conv2DLayer(\"conv1\", 32, (3, 3), padding='same', activation='relu'))\n",
    "net.add(Conv2DLayer(\"conv2\", 32, (3, 3), activation='relu'))\n",
    "net.add(MaxPool2DLayer(\"pool1\", pool_size=(2, 2), dropout=0.25))\n",
    "net.add(Conv2DLayer(\"conv3\", 64, (3, 3), padding='same', activation='relu'))\n",
    "net.add(Conv2DLayer(\"conv4\", 64, (3, 3), activation='relu'))\n",
    "net.add(MaxPool2DLayer(\"pool2\", pool_size=(2, 2), dropout=0.25))\n",
    "net.add(FlattenLayer(\"flatten\"))\n",
    "net.add(Layer(\"hidden1\", 512, activation='relu', vshape=(16, 32), dropout=0.5))\n",
    "net.add(Layer(\"output\", num_classes, activation='softmax'))\n",
    "net.connect()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model = net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['base/js/namespace'], function(Jupyter) {\n",
       "    Jupyter.notebook.kernel.comm_manager.register_target('conx_svg_control', function(comm, msg) {\n",
       "        comm.on_msg(function(msg) {\n",
       "            var data = msg[\"content\"][\"data\"];\n",
       "            var images = document.getElementsByClassName(data[\"class\"]);\n",
       "            for (var i = 0; i < images.length; i++) {\n",
       "                images[i].setAttributeNS(null, \"href\", data[\"href\"]);\n",
       "            }\n",
       "        });\n",
       "    });\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50d81fb826741b8ae32f0be10592fe6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.build_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11418207,\n",
       " 0.096262164,\n",
       " 0.10081588,\n",
       " 0.102906,\n",
       " 0.095634915,\n",
       " 0.086578459,\n",
       " 0.10232524,\n",
       " 0.092678986,\n",
       " 0.11052275,\n",
       " 0.098093539]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   166\t        self.multi_inputs = isinstance(self.inputs, (list, tuple))\r\n",
      "  1166\t            last_connections_up = False\r\n"
     ]
    }
   ],
   "source": [
    "! cat -n /usr/local/lib/python3.5/dist-packages/conx/network.py | grep \"166\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Summary:\n",
      "   length  : 50000\n",
      "   training: 50000\n",
      "   testing : 0\n",
      "   shape  : (32, 32, 3)\n",
      "   range  : (0.0, 1.0)\n",
      "Target Summary:\n",
      "   length  : 50000\n",
      "   training: 50000\n",
      "   testing : 0\n",
      "   shape  : (10,)\n",
      "   range  : (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "net.set_dataset_direct(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.088147201,\n",
       " 0.10058928,\n",
       " 0.10538228,\n",
       " 0.10751828,\n",
       " 0.097152099,\n",
       " 0.10283579,\n",
       " 0.10297485,\n",
       " 0.10017712,\n",
       " 0.092835188,\n",
       " 0.10238792]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "1091/1562 [===================>..........] - ETA: 128s - loss: 1.9512 - acc: 0.2755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d7688794956b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                         validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/dblank/conx/notebooks/saved_models/keras_cifar10_trained_model.h5 \n",
      "Model Accuracy = 0.39\n",
      "Actual Label = cat vs. Predicted Label = frog\n",
      "Actual Label = ship vs. Predicted Label = deer\n",
      "Actual Label = ship vs. Predicted Label = frog\n",
      "Actual Label = airplane vs. Predicted Label = ship\n",
      "Actual Label = frog vs. Predicted Label = deer\n",
      "Actual Label = frog vs. Predicted Label = horse\n",
      "Actual Label = automobile vs. Predicted Label = truck\n",
      "Actual Label = frog vs. Predicted Label = automobile\n",
      "Actual Label = cat vs. Predicted Label = automobile\n",
      "Actual Label = automobile vs. Predicted Label = truck\n",
      "Actual Label = airplane vs. Predicted Label = automobile\n",
      "Actual Label = truck vs. Predicted Label = truck\n",
      "Actual Label = dog vs. Predicted Label = truck\n",
      "Actual Label = horse vs. Predicted Label = ship\n",
      "Actual Label = truck vs. Predicted Label = automobile\n",
      "Actual Label = ship vs. Predicted Label = automobile\n",
      "Actual Label = dog vs. Predicted Label = automobile\n",
      "Actual Label = horse vs. Predicted Label = dog\n",
      "Actual Label = ship vs. Predicted Label = airplane\n",
      "Actual Label = frog vs. Predicted Label = truck\n",
      "Actual Label = horse vs. Predicted Label = truck\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Load label names to use in prediction results\n",
    "label_list_path = 'datasets/cifar-10-batches-py/batches.meta'\n",
    "\n",
    "\n",
    "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
    "datadir_base = os.path.expanduser(keras_dir)\n",
    "if not os.access(datadir_base, os.W_OK):\n",
    "    datadir_base = os.path.join('/tmp', '.keras')\n",
    "label_list_path = os.path.join(datadir_base, label_list_path)\n",
    "\n",
    "with open(label_list_path, mode='rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Evaluate model with test data set and share sample prediction results\n",
    "evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
    "\n",
    "predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "for predict_index, predicted_y in enumerate(predict_gen):\n",
    "    actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n",
    "    predicted_label = labels['label_names'][np.argmax(predicted_y)]\n",
    "    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n",
    "                                                          predicted_label))\n",
    "    if predict_index == num_predictions:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
